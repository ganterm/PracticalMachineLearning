<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<title>Human Activity Recognition Model</title>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>


</head>

<body>

<h1 class="title">Human Activity Recognition Model</h1>
<h4 class="author">by Markus Ganter - 05/20/2015</a></em></h4>

<p>&nbsp;</p>
<h2>Introduction</h2>
<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).</p>

<p>&nbsp;</p>
<h2>Libraries</h2>

<p>Load the required libraries</p>

<pre class="r"><code>library(caret)
library(randomForest)
library(kernlab)
library(corrplot)
</code></pre>

<p>&nbsp;</p>
<h2>Data load</h2>

<p>Download the two CSV files from <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a> and <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a> and load them.</p> 
<pre class="r"><code># read training csv 
data_training <- read.csv("./sourcedata/pml-training.csv", na.strings= c("NA",""," "))
# read testing csv
data_test <- read.csv("./sourcedata/pml-testing.csv", na.strings= c("NA",""," "))
# show the data fields 
names(data_training)
</code></pre>

<pre><code>
[1] "X"                        "user_name"                "raw_timestamp_part_1"     "raw_timestamp_part_2"    
  [5] "cvtd_timestamp"           "new_window"               "num_window"               "roll_belt"               
  [9] "pitch_belt"               "yaw_belt"                 "total_accel_belt"         "kurtosis_roll_belt"      
 [13] "kurtosis_picth_belt"      "kurtosis_yaw_belt"        "skewness_roll_belt"       "skewness_roll_belt.1"    
 [17] "skewness_yaw_belt"        "max_roll_belt"            "max_picth_belt"           "max_yaw_belt"            
 [21] "min_roll_belt"            "min_pitch_belt"           "min_yaw_belt"             "amplitude_roll_belt"     
 [25] "amplitude_pitch_belt"     "amplitude_yaw_belt"       "var_total_accel_belt"     "avg_roll_belt"           
 [29] "stddev_roll_belt"         "var_roll_belt"            "avg_pitch_belt"           "stddev_pitch_belt"       
 [33] "var_pitch_belt"           "avg_yaw_belt"             "stddev_yaw_belt"          "var_yaw_belt"            
 [37] "gyros_belt_x"             "gyros_belt_y"             "gyros_belt_z"             "accel_belt_x"            
 [41] "accel_belt_y"             "accel_belt_z"             "magnet_belt_x"            "magnet_belt_y"           
 [45] "magnet_belt_z"            "roll_arm"                 "pitch_arm"                "yaw_arm"                 
 [49] "total_accel_arm"          "var_accel_arm"            "avg_roll_arm"             "stddev_roll_arm"         
 [53] "var_roll_arm"             "avg_pitch_arm"            "stddev_pitch_arm"         "var_pitch_arm"           
 [57] "avg_yaw_arm"              "stddev_yaw_arm"           "var_yaw_arm"              "gyros_arm_x"             
 [61] "gyros_arm_y"              "gyros_arm_z"              "accel_arm_x"              "accel_arm_y"             
 [65] "accel_arm_z"              "magnet_arm_x"             "magnet_arm_y"             "magnet_arm_z"            
 [69] "kurtosis_roll_arm"        "kurtosis_picth_arm"       "kurtosis_yaw_arm"         "skewness_roll_arm"       
 [73] "skewness_pitch_arm"       "skewness_yaw_arm"         "max_roll_arm"             "max_picth_arm"           
 [77] "max_yaw_arm"              "min_roll_arm"             "min_pitch_arm"            "min_yaw_arm"             
 [81] "amplitude_roll_arm"       "amplitude_pitch_arm"      "amplitude_yaw_arm"        "roll_dumbbell"           
 [85] "pitch_dumbbell"           "yaw_dumbbell"             "kurtosis_roll_dumbbell"   "kurtosis_picth_dumbbell" 
 [89] "kurtosis_yaw_dumbbell"    "skewness_roll_dumbbell"   "skewness_pitch_dumbbell"  "skewness_yaw_dumbbell"   
 [93] "max_roll_dumbbell"        "max_picth_dumbbell"       "max_yaw_dumbbell"         "min_roll_dumbbell"       
 [97] "min_pitch_dumbbell"       "min_yaw_dumbbell"         "amplitude_roll_dumbbell"  "amplitude_pitch_dumbbell"
[101] "amplitude_yaw_dumbbell"   "total_accel_dumbbell"     "var_accel_dumbbell"       "avg_roll_dumbbell"       
[105] "stddev_roll_dumbbell"     "var_roll_dumbbell"        "avg_pitch_dumbbell"       "stddev_pitch_dumbbell"   
[109] "var_pitch_dumbbell"       "avg_yaw_dumbbell"         "stddev_yaw_dumbbell"      "var_yaw_dumbbell"        
[113] "gyros_dumbbell_x"         "gyros_dumbbell_y"         "gyros_dumbbell_z"         "accel_dumbbell_x"        
[117] "accel_dumbbell_y"         "accel_dumbbell_z"         "magnet_dumbbell_x"        "magnet_dumbbell_y"       
[121] "magnet_dumbbell_z"        "roll_forearm"             "pitch_forearm"            "yaw_forearm"             
[125] "kurtosis_roll_forearm"    "kurtosis_picth_forearm"   "kurtosis_yaw_forearm"     "skewness_roll_forearm"   
[129] "skewness_pitch_forearm"   "skewness_yaw_forearm"     "max_roll_forearm"         "max_picth_forearm"       
[133] "max_yaw_forearm"          "min_roll_forearm"         "min_pitch_forearm"        "min_yaw_forearm"         
[137] "amplitude_roll_forearm"   "amplitude_pitch_forearm"  "amplitude_yaw_forearm"    "total_accel_forearm"     
[141] "var_accel_forearm"        "avg_roll_forearm"         "stddev_roll_forearm"      "var_roll_forearm"        
[145] "avg_pitch_forearm"        "stddev_pitch_forearm"     "var_pitch_forearm"        "avg_yaw_forearm"         
[149] "stddev_yaw_forearm"       "var_yaw_forearm"          "gyros_forearm_x"          "gyros_forearm_y"         
[153] "gyros_forearm_z"          "accel_forearm_x"          "accel_forearm_y"          "accel_forearm_z"         
[157] "magnet_forearm_x"         "magnet_forearm_y"         "magnet_forearm_z"         "classe"     
</pre></code>

<p>&nbsp;</p>
<h2>Data preprocessing</h2> 

<p>Remove NAs and identifier columns.</p>

<pre class="r"><code># training data
data_training_no_NAs <- apply(data_training, 2, function(x) {sum(is.na(x))})
data_training_cleaned <- data_training[,which(data_training_no_NAs == 0)]
data_training_cleaned <- data_training_cleaned[8:length(data_training_cleaned)]
# test data
data_test_no_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_cleaned <- data_test[,which(data_test_no_NAs == 0)]
data_test_cleaned <- data_test_cleaned[8:length(data_test_cleaned)]
</code></pre>

<p>&nbsp;</p>
<h2>Model</h2>

<p>The test data set was split up into training and cross validation sets in a 70:30 ratio in order to train the model and then test it against data it was not specifically fitted to.</p>

<pre class="r"><code># splitting test data into training and cross validation
inTraining <- createDataPartition(y = data_training_cleaned$classe, p = 0.7, list = FALSE)
training <- data_training_cleaned[inTraining, ]
crossvalidation <- data_training_cleaned[-inTraining, ]</code></pre>

<p>Created a correlation plot was produced to see how strong the variables correlate with each other.</p>

<pre class="r"><code>correlationMatrix <- cor(training[, -length(training)])
corrplot(correlationMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))</code></pre>

<img src="http://ganterm.github.io/PracticalMachineLearning/rplot_zoom.png">

<p>Dark red dots indicate a highly negative and the dark red dots indicate a positive relationship between the variables. 
Based on the outcome I decided to included all variables in the model.</p>

<p>Fitting the model</p>

<pre class="r"><code># fit a model to predict the classe
model <- randomForest(classe ~ ., data = training)
# print out model 
model
</code></pre>
<pre><code>Call:
 randomForest(formula = classe ~ ., data = training) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 7

        OOB estimate of  error rate: 0.54%
Confusion matrix:
     A    B    C    D    E class.error
A 3901    3    0    1    1 0.001280082
B   14 2638    6    0    0 0.007524454
C    0   16 2377    3    0 0.007929883
D    0    0   23 2227    2 0.011101243
E    0    0    0    5 2520 0.001980198</pre></code> 


<p>This results in an OOB error rate of .56% which is quite good.</p> 

<p>&nbsp;</p>
<h2>Cross-validation</h2>

<p>Use model to classify the remaining 30% of data. The results were placed in a confusion matrix with the actual classifications to determine the accuracy of the model.</p>

<pre class="r"><code>predictCrossValidation <- predict(model, crossvalidation)
confusionMatrix(crossvalidation$classe, predictCrossValidation)
</code></pre>

<pre><code>Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1670    4    0    0    0
         B    5 1128    6    0    0
         C    0    4 1020    2    0
         D    0    0   11  953    0
         E    0    0    0    4 1078

Overall Statistics
                                          
               Accuracy : 0.9939          
                 95% CI : (0.9915, 0.9957)
    No Information Rate : 0.2846          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9923          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9970   0.9930   0.9836   0.9937   1.0000
Specificity            0.9990   0.9977   0.9988   0.9978   0.9992
Pos Pred Value         0.9976   0.9903   0.9942   0.9886   0.9963
Neg Pred Value         0.9988   0.9983   0.9965   0.9988   1.0000
Prevalence             0.2846   0.1930   0.1762   0.1630   0.1832
Detection Rate         0.2838   0.1917   0.1733   0.1619   0.1832
Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
Balanced Accuracy      0.9980   0.9953   0.9912   0.9958   0.9996
</pre></code>

<p>The result is a 99.39% prediction accuracy!</p> 

<p>&nbsp;</p>
<h2>Predictions</h2>

<p>Use the model to predict the classifications of the 20 test cases in the test data loaded above.</p> 

<pre class="r"><code># predict the classes of the test set
predictTest <- predict(model, data_test_cleaned)
# print out results
predictTest</code></pre>
<code><pre> 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
 B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
Levels: A B C D E</code></pre>
<p>&nbsp;</p>
<h2>Conclusions</h2>

<p>Using the data to create a robust model it is possible to predict how well an individual preforming various exercises.</p>


</body>
</html>
